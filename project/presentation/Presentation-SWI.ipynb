{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import nbpresent\n",
    "\n",
    "nbpresent.__version__\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "525a9f09-ce68-4262-9980-03fd9ca469d6"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Search with Inference\n",
    "---\n",
    "\n",
    "\n",
    "### GA SG Data Science 5 - Project\n",
    "\n",
    "## Matthew A. Snell\n",
    "\n",
    "#### 2017-10-21\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c6c04bf2-8cae-40ff-9c53-9cde0bd023fd"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Objective\n",
    "\n",
    "---\n",
    "\n",
    "Leverage Ngrams plus TensorFlow (Word2Vec) to rank a body of *sources* against a provided search *phrase*\n",
    "\n",
    "  - Rank Sources using Ngram based scoring (width of 3)\n",
    "    \n",
    "  - Suppliment Ngram search with Word2Vec Skipgram **Link** most likely nearest neighbours based *augmentation* of search term\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Long-Term Objective\n",
    "\n",
    "## Build a Personal (Self-Hosted) Search Engine\n",
    "\n",
    "### Indexes and searches preferred and personal data sources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Data Sources Can Include (Directly or via Plugins)\n",
    "\n",
    "  - AV Metadata\n",
    "  - Personal Files/Directories\n",
    "    - eg. DOC, ODF, PDF, TXT, CSV, MOBI, EPUB, code\n",
    "  - IMAP / Email Accounts\n",
    "  - Evernote, Wallby, Pocket\n",
    "  - RSS Feeds\n",
    "  - Webbrowser Bookmarks and History\n",
    "  - Social Media Streams and/or *Pages* or Subscriptions\n",
    "    - eg. FB, Twitter, Reddit Subs etc\n",
    "  - Online Storage\n",
    "    - eg. Dropbox, GDrive, Box, pCloud, iCloud, WebDAV (Nextcloud, ownCloud) etc\n",
    "  - Any Data Store with a defined API, authentication (eg OAUTH) and/or open (or documented) standards\n",
    "\n",
    "#### Functionality Extendable via Plugins\n",
    "\n",
    "  - P2P, Prediction and related sources etc\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b8757629-3956-475f-bd5a-12458400ee7d"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lessons Learnt ... *So Far* ...\n",
    "\n",
    "---\n",
    "\n",
    "  - Who needs classes? It's just a proof of concept\n",
    "\n",
    "    **Wrong** - Code Complexity\n",
    "    \n",
    "  - Who needs a DBMS? It's just a proof of concept\n",
    "\n",
    "    **Wrong** - Performance\n",
    "      \n",
    "  - ETL (cleansing) is slow (cpu time)\n",
    "\n",
    "    **Get the Data Models Right** - Re-Runs & Validators are expensive\n",
    "    \n",
    "  - Dictionaries `dict()` or `{ k:v }` are Great!\n",
    "   \n",
    "   **Nested Dictionaries are (code) Messy**:\n",
    "   \n",
    "   `dict = { k1: { k2: { k3: v }}}` -> `dict[k1][k2][k3]`\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lessons Learnt ... *So Far* ... (cont..)\n",
    "\n",
    "---\n",
    "    \n",
    "     \n",
    "  - I'll build a non/semi-Data Science model 1st for comparision\n",
    "\n",
    "    **Time Consuming** - More about Python than Data Science\n",
    "\n",
    "  - RegEx - Need I say more...\n",
    "  \n",
    "  - I don't know how to describe Data Science...\n",
    "  \n",
    "    - But I know what it is when I see it...\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is an Ngram?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For the purposes of Data Science or NLP, an Ngram (monogram, bigram, trigram, quadgram etc) is a *sliding* group of *words* taken from a set of text.\n",
    "\n",
    "eg. *using:* **`consider this line of text`**\n",
    "```\n",
    "    1gram = 5 items - [ consider, this, line, of, text ]\n",
    "\n",
    "    2gram = 4 items - [ consider this, this line, line of, of text ]\n",
    "\n",
    "    3gram = 3 items - [ consider this line, this line of, line of text ]\n",
    "    \n",
    "    Total = 12 potential Ngrams to leverage\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# But for Search Phases,\n",
    "# We handle Ngrams differently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How a search phrase is sequenced or weighted by a user can be very different compared to how the terms are used.\n",
    "\n",
    "Consider:\n",
    "\n",
    "**Search Phrase:** `Python Learning Examples SciKit Data Science`\n",
    "\n",
    "vs\n",
    "         \n",
    "**Book Title:** `Data Science and SciKit: Learning through Python with Examples`\n",
    "\n",
    "Using Ngrams, the best hit we get beyond 1gram (low scoring), is the 2gram `Data Science` - in a sea of documents, this will not rank high - unless a word is rare eg `scikit`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To counter this, for *search phrases*, we generate every possible Ngram, to given width, and drop all those never seen before (ie. not in our Ngram Datastore)\n",
    "\n",
    "eg. `Python Learning Examples SciKit Data Science` ->\n",
    "\n",
    "```\n",
    "[ data, data examples, data examples learning, data examples python, data examples science, data examples scikit, data learning, data learning examples, data learning python, data learning science, data learning scikit, data python, data python examples, data python learning, data python science, data python scikit, data science, data science examples, data science learning, data science python, data science scikit, data scikit, data scikit examples, data scikit learning, data scikit python, data scikit science, examples, examples data, examples data learning, examples data python, examples data science, examples data scikit, examples learning, examples learning data, examples learning python, examples learning science, examples learning scikit, examples python, examples python data, examples python learning, examples python science, examples python scikit, examples science, examples science data, examples science learning, examples science python, examples science scikit, examples scikit, examples scikit data, examples scikit learning, examples scikit python, examples scikit science, learning, learning data, learning data examples, learning data python, learning data science, learning data scikit, learning examples, learning examples data, learning examples python, learning examples science, learning examples scikit, learning python, learning python data, learning python examples, learning python science, learning python scikit, learning science, learning science data, learning science examples, learning science python, learning science scikit, learning scikit, learning scikit data, learning scikit examples, learning scikit python, learning scikit science, python, python data, python data examples, python data learning, python data science, python data scikit, python examples, python examples data, python examples learning, python examples science, python examples scikit, python learning, python learning data, python learning examples, python learning science, python learning scikit, python science, python science data, python science examples, python science learning, python science scikit, python scikit, python scikit data, python scikit examples, python scikit learning, python scikit science, science, science data, science data examples, science data learning, science data python, science data scikit, science examples, science examples data, science examples learning, science examples python, science examples scikit, science learning, science learning data, science learning examples, science learning python, science learning scikit, science python, science python data, science python examples, science python learning, science python scikit, science scikit, science scikit data, science scikit examples, science scikit learning, science scikit python, scikit, scikit data, scikit data examples, scikit data learning, scikit data python, scikit data science, scikit examples, scikit examples data, scikit examples learning, scikit examples python, scikit examples science, scikit learning, scikit learning data, scikit learning examples, scikit learning python, scikit learning science, scikit python, scikit python data, scikit python examples, scikit python learning, scikit python science, scikit science, scikit science data, scikit science examples, scikit science learning, scikit science python ]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Datastores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Config\n",
    "Contains application wide baselines (eg. Instance UUID, Corpus Directory, Ngram width, Word2Vec Ngram Width) & master keys (currently only last used `vector`)\n",
    "\n",
    "---\n",
    "\n",
    "### Dictionary\n",
    "`word` to `vector` (`int`) mappings\n",
    "`vector` assigned sequentially when new `word` is found\n",
    "\n",
    "---\n",
    "\n",
    "### Vector\n",
    "`vector`  (`int`) to `word` mappings\n",
    "\n",
    "---\n",
    "\n",
    "### NGram\n",
    "Per `ngram`, per `srcID` list of lines with Ngram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sources\n",
    "Per Source Path (file path, URL etc) to `srcID` (UUID)\n",
    "\n",
    "Potential to add source hash (MD5 or SHA1) to itentify duplicates or alternate sources\n",
    "\n",
    "---\n",
    "\n",
    "### DocMeta (Document Meta)\n",
    "Per `source` summary information, including type (URL, FILE, ...) and sub-type (HTML, PDF, TXT, CSV, ...), index status, Word2Vec status, `list` of ngrams, indexed data version, when indexed etc\n",
    "\n",
    "---\n",
    "\n",
    "### DocStat (Document Statistics)\n",
    "Per document (`srcID`), per line list of Ngrams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Algorithm - Normalise Text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Normalise Text\n",
    "\n",
    "---\n",
    "\n",
    "convert to lowercase plus RegEx;\n",
    "```\n",
    "# remove apostrophe in words: [alpha]'[alpha]=[alpha][alpha]\n",
    "# eg. don't = dont\n",
    "norm_text = re.sub(r'([\\w]+)[\\`\\']([\\w]+)', r'\\1\\2', norm_text)\n",
    "\n",
    "# Replace non-AlphaNumeric sequences with Space\n",
    "norm_text = re.sub(r'[^\\w]+', r' ', norm_text)\n",
    "\n",
    "# Replace spaces, underscores, tabs, newlines and return\n",
    "# sequences with a space (mostly redundant except for '_')\n",
    "norm_text = re.sub(r'[ _\\t\\n\\r]+', r' ', norm_text)\n",
    "\n",
    "# Replace pure digits with space eg 1234, but not 4u or best4u\n",
    "norm_text = re.sub(r'^\\d+$|^\\d+\\W+|\\W+\\d+\\W+|\\W+\\d+$', r' ', norm_text)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Algorithm - Index - Ngram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Per Line in File/Source;\n",
    "\n",
    "  - Normalise\n",
    "  \n",
    "  - Remove *Stop Words* (eg. and, it, for, a)\n",
    "  \n",
    "  - Break into 1gram to Ngrams (Currently 3gram)\n",
    "  \n",
    "  - Add 1gram (words) to Dictionary/Vector Datastore\n",
    "  \n",
    "  - Add to Ngram Datastore (Ngram & *Source*)\n",
    "  \n",
    "  - Add Ngram's existence to DocMeta Datastore\n",
    "  \n",
    "  - Add Ngram & LineID (No.) to DocStat for *Source*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Algorithm - Word2Vec\n",
    "\n",
    "As at 11am Oct 21st - Broken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Per File/Pseudo Line;\n",
    "\n",
    "  - Normalise\n",
    "\n",
    "  - Build Frequency List `[ [word, 5] ]`\n",
    "  \n",
    "  - Vectorized List `\"sample sentence\"` -> `[ 17634, 23654 ]`\n",
    "\n",
    "  - Load/Initialize TensorFlow\n",
    "  \n",
    "  - Perform 10,0000 Interations of Skipgram Algorithm\n",
    "    - (word-1, word, word+1) -> calculate nearest neighbours likliehood\n",
    "  \n",
    "  - Save Model\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Producted vectorList:**\n",
    "\n",
    "2, 79985, 79981, 4, 3, 6, 8, 7, 9, 8, 9, 6, 10, 7, 10, 6, 11, 7, 11, 6, 15, 7, 15, 12, 14, 13, 6, 16, 7, 16, 18, 19, 20, 21, 17, 6, 23, 7, 23, 22, 6, 24, 25, 24, 6, 26, 7, 26, 6, 27, 7, 27, 6, 28, 7, 28, 6, 29, 7, 29, 30, 6, 31, 7, 31, 6, 32, 7, 32, 33, 6, 34, 7, 34, 6, 35, 7, 35, 6, 36, 7, 36, 6, 37, 7, 37, 6, 39, 7, 29, 39, 40, 38, 41, 6, \n",
    "42, 25, 42, 6, 43...\n",
    "\n",
    "**Produced wordCount:**\n",
    "\n",
    "['fawn', 1], ['unattackable', 1], ['middleman', 1], ['yellow', 4], ['narcotic', 1], ['four', 4], ['prices', 1], ['woods', 1], ['woody', 2], ['aggression', 2], ['marching', 1], ['looking', 1], ['eligible', 2], ['electricity', 3], ['similarity', 2], ['albumen', 1], ['immature', 1], ['antecede', 1], ['slothful', 1], ['regional', 2], ['pigment', 1], ['medicament', 1], ['disturb', 1], ['prize', 5], ['wooden', 2], ['reliable', 2], ['ornamental', 1], ['charter', 2], ['tired', 2], ['bacon', 2], ['pulse', 1], ['empirical', 2], ['elegant', 2], ['second', 7], ['tether', 1], ['horseshoe', 1], ['inanimate', 1], ['errors', 1], ['medically', 1], ['widen', 3], ['cooking', 4], ['schism', 1], ['fossil', 3], ['numeral', 1], ['contributes', 1], ['inducement', 1], ['cull', 1], ['specialist', 2], ['hero', 4], ['reporter', 2]...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Algorithm - Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For Input;\n",
    "\n",
    "  - Normalise\n",
    "  \n",
    "  - Sanitise - remove duplicate words\n",
    "  \n",
    "  - Multiplex Ngram *Search Phrase*\n",
    "  \n",
    "  - Drop Unseen Ngrams (ie. not in Ngram Datastore)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For Scoring Ngram Matches;\n",
    "  \n",
    "  - Restrict calculations to statistics from *sources* with 1 or more Ngram Match\n",
    "  \n",
    "  - Rare and/or Long Ngrams Boosts a *source's* score\n",
    "    - 1gram < 2gram < ... < Ngram Weighting\n",
    "    - Scarce Ngrams > Frequent Ngrams\n",
    "  \n",
    "  - `NgramWeight = math.log(AllNgramCounts, NgramCount)`\n",
    "    - This reverses the count/frequency\n",
    "  \n",
    "  - Normalise to 0 -> 1 range \n",
    "    - `NgramWeight /= (HighestWeight - LowestWeight)`\n",
    "  \n",
    "  - *Source* Weight is sum of each Ngram contained;\n",
    "    - `SrcScore += NgramWeight * SourceAppeareances * NgramWidth`\n",
    "  \n",
    "  - Normalise *source's* score 0 -> 1 range\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Search Words;** data, dont, guide, handy, library, oregon, python, science, state, university\n",
    "\n",
    "topSrcMatches:\n",
    "```\n",
    " 1 : FILE TXT 4fb66765-... 1.0               19 .../text/Library_List.txt\n",
    " 2 : FILE CSV d37b3802-... 0.215896415671    16 .../csv/deep-nlp-Sheet_2.csv\n",
    " 3 : FILE TXT 4ca0fe9d-... 0.0394573896895    9 .../text/t8.shakespeare.txt\n",
    " 4 : FILE TXT 24076e31-... 0.00736442711495   5 .../text/CASTLE.txt\n",
    " 5 : FILE TXT 65982f57-... 0.00634658230231   7 .../text/core-wordnet.txt\n",
    " 6 : FILE TXT 67324674-... 0.00229748047626   4 .../text/rq3.txt\n",
    " 7 : FILE TXT 2022f0e4-... 0.0021464153977    4 .../text/dd_dwarf.txt\n",
    " 8 : FILE TXT 23260beb-... 0.00181603356786   5 .../text/i11.txt\n",
    " 9 : FILE TXT 3c81a474-... 0.00115478241492   9 .../text/dictionary.txt\n",
    "10 : FILE CSV 43820f0b-... 0.000982226868107  1 .../csv/deep-nlp-Sheet_1.csv\n",
    "```\n",
    "**ngrams used;**\n",
    "    data, data science, data science python, data state, dont, guide, guide data, \n",
    "    guide state, handy, library, library data, library guide, oregon, oregon state, oregon state university, \n",
    "    python, python data, python data science, science, science python, state, state university, \n",
    "    university, university library, university oregon, university python, university state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For Scoring Based on Word2Vec Skipgram;\n",
    "\n",
    "  - Take Sanitized *Search Phrase*\n",
    "    \n",
    "  - For each word, add 2 most predicted neighours by W2V skipgram\n",
    "\n",
    "  - Re-Sanitise - remove duplicate words\n",
    "  \n",
    "  - Multiplex Ngram *Search Phrase*\n",
    "  \n",
    "  - Drop Unseen Ngrams (ie. not in Ngram Datastore)\n",
    "\n",
    "  - Repeat Scoring based on Ngram Match algorithm & merge results\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Moving Forward -> Opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Index and Search\n",
    "\n",
    "---\n",
    "\n",
    "  - Word2Vec Skipgram Model - Build nGram2Vec?\n",
    "    - The more data processed, the better it gets\n",
    "    \n",
    "  - Use Word2Vec prediction against search term expansion or document scoring?\n",
    "  \n",
    "  - Identify & Improve weight based on Ngram usage\n",
    "    - eg. title, headings, tags\n",
    "    - Easier with rich/tagged sources eg. HTML `<h1>Important Heading</h1>`\n",
    "    \n",
    "  - De-Duplication or Identification of Same Material, but Different route\n",
    "    - Same, Same but Different\n",
    "    - What source is better or preferred?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Index and Search (cont...)\n",
    "\n",
    "---\n",
    " \n",
    "  - Crawler\n",
    "    - When URLs or other sources are linked, extend indexing\n",
    "    - *BackRub*\n",
    "      - Original Google Algorithm **Link**\n",
    "        - More references/link = higher score\n",
    "        - Higher Score of Link Source = Higher Score for Target\n",
    "  \n",
    "  - Language detection and Multi-Lingual Support\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Technical\n",
    "\n",
    "---\n",
    "\n",
    "  - Data Models\n",
    "  \n",
    "  - Multi-thread (currently single threaded & Batch Driven)\n",
    "  \n",
    "  - Full RDBMS backend support needed with concurrent access\n",
    "  \n",
    "  - Identify Opportunities for 1-pass vs Batch processing\n",
    "  \n",
    "    - eg. Acquire, parse, and 1gram *source*\n",
    "    \n",
    "    - Batch Ngram & Word2Vec process?\n",
    "  \n",
    "  - Language - Python vs Go? Both?\n",
    "  \n",
    "  - Stack - seperate & thread activities\n",
    "  \n",
    "    - eg UI, Acquisition, API, Analysis, Indexing, *Source* validation & updates etc\n",
    "    \n",
    "  - Multi-Lingual Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank you\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "nbpresent": {
   "slides": {
    "463ac1c5-3352-44dc-9235-23ac0d84b41e": {
     "id": "463ac1c5-3352-44dc-9235-23ac0d84b41e",
     "prev": "ee233c08-e6ea-42ae-b70c-26e7fceecfe4",
     "regions": {
      "b0072f8a-5fa6-49ff-b5b0-3976507b34eb": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "id": "b0072f8a-5fa6-49ff-b5b0-3976507b34eb"
      }
     }
    },
    "9a7e67e8-a5d4-4ab6-8c90-99f2491da797": {
     "id": "9a7e67e8-a5d4-4ab6-8c90-99f2491da797",
     "prev": "a16efaa2-3906-4e85-aee3-f814c1090edf",
     "regions": {
      "57df63df-1911-458e-b56f-47fcfd03c0b9": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "e0f89f1e-62f1-4b97-b4a4-c58d0b45e96b",
        "part": "whole"
       },
       "id": "57df63df-1911-458e-b56f-47fcfd03c0b9"
      },
      "b7939136-7386-496f-8338-742a35f927f3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b8757629-3956-475f-bd5a-12458400ee7d",
        "part": "whole"
       },
       "id": "b7939136-7386-496f-8338-742a35f927f3"
      }
     }
    },
    "a16efaa2-3906-4e85-aee3-f814c1090edf": {
     "id": "a16efaa2-3906-4e85-aee3-f814c1090edf",
     "prev": "463ac1c5-3352-44dc-9235-23ac0d84b41e",
     "regions": {
      "dc91703f-0f79-48c7-82f6-ea9c3f59ff3a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c6c04bf2-8cae-40ff-9c53-9cde0bd023fd",
        "part": "whole"
       },
       "id": "dc91703f-0f79-48c7-82f6-ea9c3f59ff3a"
      }
     }
    },
    "ee233c08-e6ea-42ae-b70c-26e7fceecfe4": {
     "id": "ee233c08-e6ea-42ae-b70c-26e7fceecfe4",
     "prev": null,
     "regions": {
      "c45c16d5-8891-4465-b55e-75ceabee2adb": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "525a9f09-ce68-4262-9980-03fd9ca469d6",
        "part": "whole"
       },
       "id": "c45c16d5-8891-4465-b55e-75ceabee2adb"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
